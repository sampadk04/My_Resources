{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is a bagging technique that trains multiple decision trees with minor modification in the split criterion.\n",
    "\n",
    "![Random Forest](./Random_Forest_1.jpeg)\n",
    "\n",
    "In case of a decision tree, we train a single decision tree, whereas in Random Forest, we train multiple decision trees on different training sets obtained through bootstrap aggregation (bagging)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Algorithm\n",
    "\n",
    "**Input:**\n",
    "\n",
    "Training data $D$ with shape $(n,m)$, where $n$ is the no. of examples and $m$ is the no. of features.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Sample $q$ datasets each of shape $(n,m)$, say $D_1, D_2. \\dots D_q$ with replacement from $D$.\n",
    "2. In each dataset $D_j$, select $u$ out of $m$, where $u \\le m$ features before each split and train a full decision tree $h_j(\\vec{x})$.\n",
    "3. The final predictor is\n",
    "    - For regression, an average output from $q$ regressors is assigned to the new example:\n",
    "    $$h(\\vec{x}) = \\frac{1}{q}\\sum_{j=1}^{q} h_j(\\vec{x}) $$\n",
    "    - For classification, a majority voting is taken and the class label with maximum no. of votes is assigned to the new example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "In order to keep the implementation focused to the main components of random forest, we make use of `DecisionTreeClassifier` from `sklearn.tree` module for the decision tree component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build the code component-wise and finally combine them into `RondomForest` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "We define a function for bagging - creating $q$ bootstrap samples $D_1, D_2, \\dots D_q$ from the original dataset $D$:\n",
    "- The key step is `np.random.choice` with `size=n_samples` and `replace=True` which ensures that the bootstrap sample has the same number of samples as the original dataset and it is obtained by sampling with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag(X,y):\n",
    "    # Counts the no. of rows in the feature matrix\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Generates a random sample from the given input.\n",
    "    indices = np.random.choice(\n",
    "        n_samples,\n",
    "        size=n_samples,\n",
    "        replace=True\n",
    "    )\n",
    "    # Note that the second argument size has been set to the size of the original sample dataset and replacement has been set to True\n",
    "    # This will allow repitition of indices\n",
    "\n",
    "    return X[indices],y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting\n",
    "\n",
    "Code up `most_common_label` function for obtaining majority vote for class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_label(y):\n",
    "    counter = Counter(y)\n",
    "    most_common = counter.most_common(1)[0][0]\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Class\n",
    "\n",
    "We create `RandomForest` class with the following default parameters:\n",
    "- no. of tree = 10\n",
    "- minimum no. of samples = 2\n",
    "- maximum depth = 100\n",
    "\n",
    "The `max_features` is a configurable parameter that can be set by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, min_samples_split=2, max_depth=100, max_features=None):\n",
    "        # hyperparameter for fixing no. of trees to be generated\n",
    "        self.n_trees=n_trees\n",
    "        # min no. of samples required for split\n",
    "        self.min_samples_split=min_samples_split\n",
    "        # max depth of decison tree\n",
    "        self.max_depth=max_depth\n",
    "        # max no. of features to be considered\n",
    "        self.max_features=max_features\n",
    "        self.trees = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random Forest\n",
    "\n",
    "We implement `fit` method.\n",
    "- Initialize an empty list of decision tree classifiers.\n",
    "- In the for loop, we train each decision tree with parameters set from the andom forest on a bootstrapped sample obtained via the `bag` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fit(self, X,y):\n",
    "        # Empty array of tree which gets filled in during operation\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            # We will now make RF class inherit features from sklearn.tree.DecisionTreeClassifier\n",
    "            tree = DecisionTreeClassifier(\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                max_depth=self.max_depth,\n",
    "                max_features=self.max_features\n",
    "            )\n",
    "            X_sample, y_sample = bag(X,y)\n",
    "            tree.fit(X_sample,y_sample)\n",
    "            # We append each of these trees\n",
    "            self.trees.append(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Let's implement the `predict` function.\n",
    "\n",
    "Here, we need to note that each of the trees will be give predictions for all the individual rows of the input data.\n",
    "\n",
    "For example, if we have random forest with $3$ trees and $2$ classes `0` and `1`, let's assume the prediction for $5$ samples is as follows:\n",
    "- Tree 1 gives `11001`\n",
    "- Tree 2 gives `00111`\n",
    "- Tree 3 gives `10101`\n",
    "\n",
    "We need to aggregate the output for the respective samples and take an average/majority vote. For this, we will use `np.swapaxes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, X):\n",
    "        # Converting the list of predictions from the models into a numpy array\n",
    "        tree_predict = np.array([tree.predict(X) for tree in self.trees])\n",
    "        # Each tree will give out its own predictions\n",
    "        tree_predict = np.swapaxes(tree_predict, 0, 1)\n",
    "        # After swapping the axes, each row in tree_predict, contains the predictions of a partical input w.r.t. all the trees\n",
    "        y_pred = [most_common_label(tree_pred) for tree_pred in tree_predict]\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Cleaned Up Code\n",
    "\n",
    "Combining different components for creating the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def bag(X,y):\n",
    "    # Counts the no. of rows in the feature matrix\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Generates a random sample from the given input.\n",
    "    indices = np.random.choice(\n",
    "        n_samples,\n",
    "        size=n_samples,\n",
    "        replace=True\n",
    "    )\n",
    "    # Note that the second argument size has been set to the size of the original sample dataset and replacement has been set to True\n",
    "    # This will allow repitition of indices\n",
    "\n",
    "    return X[indices],y[indices]\n",
    "\n",
    "def most_common_label(y):\n",
    "    counter = Counter(y)\n",
    "    most_common = counter.most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, min_samples_split=2, max_depth=100, max_features=None):\n",
    "        # hyperparameter for fixing no. of trees to be generated\n",
    "        self.n_trees=n_trees\n",
    "        # min no. of samples required for split\n",
    "        self.min_samples_split=min_samples_split\n",
    "        # max depth of decison tree\n",
    "        self.max_depth=max_depth\n",
    "        # max no. of features to be considered\n",
    "        self.max_features=max_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        # Empty array of tree which gets filled in during operation\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            # We will now make RF class inherit features from sklearn.tree.DecisionTreeClassifier\n",
    "            tree = DecisionTreeClassifier(\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                max_depth=self.max_depth,\n",
    "                max_features=self.max_features\n",
    "            )\n",
    "            X_sample, y_sample = bag(X,y)\n",
    "            tree.fit(X_sample,y_sample)\n",
    "            # We append each of these trees\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Converting the list of predictions from the models into a numpy array\n",
    "        tree_predict = np.array([tree.predict(X) for tree in self.trees])\n",
    "        # Each tree will give out its own predictions\n",
    "        tree_predict = np.swapaxes(tree_predict, 0, 1)\n",
    "        # After swapping the axes, each row in tree_predict, contains the predictions of a partical input w.r.t. all the trees\n",
    "        y_pred = [most_common_label(tree_pred) for tree_pred in tree_predict]\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate our implementation of Random Forest on a real world dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true==y_pred)/len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "X,y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=69)\n",
    "\n",
    "clf = RandomForest(n_trees=10, max_depth=10, max_features='sqrt')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_hat = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_test_hat)\n",
    "\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at other evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51  3]\n",
      " [ 1 59]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, y_test_hat)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        54\n",
      "           1       0.95      0.98      0.97        60\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(matrix)\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee0777041ec98f607d7fd5b29a894c71a8ff0325c3258b55f9f8e1ee2f7fef34"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('skk-mlp-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
